[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "The purpose of this site is to share some experiences and thoughts about teaching MBA students how generative AI can and is being used in the finance industry and how they can leverage it to be more efficient in the workplace. We are all learning this on the fly, and of course things are evolving very quickly, so I’m hoping that sharing will be useful. I invite everyone to share in the comments section below.\nI teach a six-week 18-contact-hour course to first year MBAs in the last part of their first year. For the most part, I do not teach new financial concepts in the course, because we have other courses for those. However, I try to reinforce students’ understanding of concepts they have already seen by approaching them with a different tool (AI + coding). The course caps a first-year sequence consisting of a one-semester core course in the fall followed by an ‘Applied Finance’ course in the first part of the spring that goes deeper into some of the topcs covered in the core course and develops spreadsheet modeling skills, and then my course in the last part of the spring that covers the same topics again, but using AI + coding instead of spreadsheets. I will describe that course in particular, but many of the observations below should apply to courses in other formats and to courses for different student groups.\nIn addition to conducting financial analysis directly with AI + coding, the course uses AI + coding to develop tools for financial analysis. The basic structure, as is described in more detail below, is \\[\\text{Chatbots} \\; \\rightarrow \\; \\text{Coding} \\; \\rightarrow \\; \\text{Apps} \\; \\rightarrow \\; \\text{Custom Chatbots} \\; \\rightarrow \\; \\text{AI Agents}\\] In each step, we use examples from finance, but this same structure would apply to any domain."
  },
  {
    "objectID": "index.html#course-intro",
    "href": "index.html#course-intro",
    "title": "",
    "section": "Course Intro",
    "text": "Course Intro\nA good demonstration at the start of a course on Finance with AI is to upload a company’s annual report to ChatGPT (or a different chatbot) and ask it for an investment analysis in the form of a Word document. You can ask the chatbot to include the following:\n\na summary of the annual report\na comparison of the firm to peer firms\na two-stage DCF analysis formed by extrapolating trends\na sensitivity analysis focused on the items for which extrapolation might be most unreasonable\na buy/hold/sell recommendation\n\nThis example illustrates the power of AI ‘out of the box’ for financial analysis. It also explains why we are seeing so many stories about the potential demise of junior financial analysts. Of course, the AI is not perfect. We should engage our students in a discussion of how the report can be improved.\nCompile the responses to build a more detailed prompt than the original prompt, start a new chatbot session (so the LLM will have no memory of the original prompt and response1), and submit the new prompt. Compare the results. Get students to discuss how they might further improve the new prompt. Then, point out that the eventual prompt that they form through this iterative process can be saved as a text file and uploaded each time they want to generate this type of report. This is prompt engineering."
  },
  {
    "objectID": "index.html#main-topics",
    "href": "index.html#main-topics",
    "title": "",
    "section": "Main Topics",
    "text": "Main Topics\nThe course covers the following topics:\n\nPrompt engineering\nCorporate implementations of AI\nUsing AI to write code for financial analysis, visualization, and report generation\nUsing AI to create apps to automate the above\nCreating custom chatbots for the above\nCreating AI agents for the above\nIn-depth study of using AI for DCF valuation of companies"
  },
  {
    "objectID": "index.html#tools",
    "href": "index.html#tools",
    "title": "",
    "section": "Tools",
    "text": "Tools\nStudents can use any chatbot for the first part of the course. Then, the course switches to using Google Colab, which is a free Python environment in the cloud that has built-in Google Gemini assistance. There is no software to install, so there is no set-up required. I prepared some materials to show students how to use Google Colab, which I cover when we get to that point.\nFor the last part of the course, students need an OpenAI account. They can use the free version. They will need to get an API key, for which charges are on a per-usage basis. The charges are minimal for the experimentation that is done in the course.\nPreviously, I used Julius.ai instead of Google Colab It is a bit simpler to use, because it is a simple chatbot interface rather than a Jupyter notebook - see my blog post about Julius. Julius also provides access to LLMs from OpenAI and Anthropic, whereas Colab only offers Google Gemini. However, while Anthropic’s Claude is still the best coding LLM, Gemini has caught up considerably and is now a solid choice. Furthermore, Colab offers several advantages: it is free, it produces Jupyter notebooks that are portable, and it can deploy apps to the cloud."
  },
  {
    "objectID": "index.html#first-topic-writing-code",
    "href": "index.html#first-topic-writing-code",
    "title": "",
    "section": "First Topic: Writing Code",
    "text": "First Topic: Writing Code\nTwo good exercises for the first topic are mean-variance analysis and CAPM cost of capital calculations. I demo the first and assign the second as a group project. AI can write code to get data from Yahoo Finance, calculate returns, and perform the analyses, assuming we are willing to trust sample moments in mean-variance analysis. We could also input risk and risk premia assumptions directly for mean-variance analysis rather than calculating sample moments. See my blog posts about getting data from Yahoo Finance, mean-variance analysis, and calculating the cost of capital.\nThere are natural visualization components to both exercises, namely the plot of the mean-variance frontier and the CAPM scatter plot and regression line. AI can write python code to generate Word docs and/or PowerPoint decks containing the analyses and visualizations. See this post about generating Word docs and PowerPoint decks and this post about visualizations.\nThere is a lot that could be done on option pricing if students have seen options already. As remarked above, I teach a first-year class, and I can’t preempt what will be taught to second-year students. Except for that issue, I would certainly spend some time on options."
  },
  {
    "objectID": "index.html#second-topic-building-apps",
    "href": "index.html#second-topic-building-apps",
    "title": "",
    "section": "Second Topic: Building Apps",
    "text": "Second Topic: Building Apps\nWhatever code an LLM writes for an exercise in Part 1 can be encapsulated in an app and made broadly available, so people can use the code without needing to go to Julius or Colab or any other Python platform. The Python Streamlit library makes app construction easy. The same is true of the Gradio library apparently, but I only have experience with Streamlit. See my blog post about creating apps.\nStreamlit apps can be deployed to the cloud from Google Colab using the ngrok service. Students will need to create free accounts at ngrok and get an authorization token. They should save their authorization tokens as secret keys in Google Colab (they can ask Gemini how to do that). Then, they can tell Gemini to deploy apps using ngrok.\nDeployment by ngrok is sufficient to illustrate the concept of building apps, but it is not a permanent deployment. It is probably best to leave permanent deployment as something for students to explore on their own or perhaps to cover in a special session, because it can be a bit complex. The best solution I have found is to install Claude Code and ask it to do it. However, students will need assistance even to install and use Claude Code. See my discussion of setting up and installing Claude Code."
  },
  {
    "objectID": "index.html#third-topic-building-chatbots",
    "href": "index.html#third-topic-building-chatbots",
    "title": "",
    "section": "Third Topic: Building Chatbots",
    "text": "Third Topic: Building Chatbots\nCustom chatbots involve\n\nA user interface\nAn API connection to an LLM\nA customization of user prompts\n\nSystem prompt\nPossible retrieval of documents\n\nPossible uses of tools\nPossible fine tuning\n\nCreating a user interface is a variation of building an app and has already been essentially covered. Creating an API connection to an LLM is similar to setting up ngrok as covered in the second topic. Finally, the prompt that was saved as a text file in the course introduction can easily be used to create an example of a system prompt. So, a simple custom chatbot of user interface + API connection + system prompt uses only techniques that students have already seen at this point.\nStudents can get API keys from OpenAI even with free accounts, or they can get API keys from Anthropic or Google. They can ask any chatbot how to do it. They should save their API keys as secret keys in Google Colab in the same way they saved their ngrok keys. They will be charged on a per-usage basis, but the charges will be trivial for the experimentation that is done in the course. It is also possible to get a free API key from Open Router and to use free open source LLMS from Hugging Face, so there are no charges at all.\nOnce an API key is installed on Colab, students can ask Gemini to connect to the LLM and send a prompt and get a response. Gemini will probably import the openai Python package even for using other LLMs, because the OpenAI API has become the standard. The code that Gemini has to write to use the openai package is extremely simple and transparent, and it is useful for students to see it.\nAs a next step, students can ask Gemini to create a custom chatbot using Streamlit and ngrok. A good example for a system prompt is to ask the LLM to respond in a foreign language, so students can see that the system prompt actually works. It is important that Gemini build a loop in the app that collects all past prompts and responses and sends them together with the system prompt with each new prompt. If the chatbot does not seem to be remembering past prompts during a session, it is because the loop was not constructed. Students should ask Gemini to add the loop if this occurs.\nA good topic for creating custom chatbots is valuing a company through a DCF analysis. The ultimate goal is that a user can simply ask for a valuation of a company, and the chatbot will ask appropriate questions and generate a DCF analysis, spelling out assumptions and the reasons for them and including sensitivity analyses. There are a lot of questions that one must grapple with on the way to creating such a chatbot, and it is a great way to get students to think in more detail about how to generate pro forma statements and what assumptions are reasonable in different contexts. It is worthwhile to discuss multiple Harvard-style cases in the process of refining the chatbot’s system prompt.\nThe assumptions that are used must ultimately be supplied by the user, but the chatbot can provide information - for example, trends in historical ratios - and ask the user to what extent the trends should be extrapolated or how they should be adjusted. Students can decide what ratios the chatbot should calculate use to generate the pro forma statements.\nIf we use OpenAI’s API, we get access to OpenAI’s Code Interpreter tool, which is a cloud-based Python environment. It has similar functionality to Google Colab but can be run in the background, invisible to the user. The purpose of employing the Code Interpreter is to ensure that mathematical errors are not made. LLMs are still not completely reliable for mathematical calculations.\nAn easy option for data is Yahoo Finance. Alternatively, users can be asked to upload data. It may also be possible to use other data sources, if there are available sources with APIs that can be used by the chatbot.\nI treat building a valuation API as a class project that extends over multiple class sessions. It is too complex to to be presented to students as as an assignment. However, students should be able to build chatbots for mean-variance analysis or for cost of capital calculations."
  },
  {
    "objectID": "index.html#giscus",
    "href": "index.html#giscus",
    "title": "",
    "section": "Discussions",
    "text": "Discussions\nPlease share your thoughts, experiences, or questions about teaching AI-assisted finance in the comments below."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLarge language models do not actually remember past prompts and responses in a session. Instead the record of past prompts and responses in a session is sent by a chatbot to the model along with each new prompt, so that the model can use the record of past prompts and responses when generating a new response.↩︎"
  },
  {
    "objectID": "streamlit_colab_example.html",
    "href": "streamlit_colab_example.html",
    "title": "Running Streamlit on Google Colab with pyngrok",
    "section": "",
    "text": "# Install required packages\n!pip install streamlit pyngrok\n\n\n# Create a simple Streamlit app\n%%writefile app.py\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\n\nst.title('Streamlit on Google Colab')\nst.write('This app is running on Colab with pyngrok!')\n\n# Add some interactive elements\nnumber = st.slider('Select a number', 0, 100, 50)\nst.write(f'You selected: {number}')\n\n# Create sample data\nchart_data = pd.DataFrame(\n    np.random.randn(20, 3),\n    columns=['a', 'b', 'c']\n)\n\nst.line_chart(chart_data)\n\n\n# Set up ngrok authentication (optional but recommended)\n# Get your free auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\nfrom pyngrok import ngrok\n\n# Uncomment and add your token:\n# ngrok.set_auth_token('YOUR_NGROK_AUTH_TOKEN')\n\n\n# Run Streamlit with pyngrok\nfrom pyngrok import ngrok\nimport subprocess\nimport threading\n\ndef run_streamlit():\n    subprocess.run(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n\n# Start Streamlit in background thread\nthread = threading.Thread(target=run_streamlit)\nthread.start()\n\n# Create ngrok tunnel\npublic_url = ngrok.connect(8501)\nprint(f'\\n✅ Streamlit app is running at: {public_url}')\nprint('Click the link above to access your app!')\n\n\n# Alternative: One-liner approach\n!streamlit run app.py &&gt;/dev/null&\n\nfrom pyngrok import ngrok\npublic_url = ngrok.connect(8501)\nprint(f'Streamlit URL: {public_url}')\n\n\n# To kill the tunnel when done\nngrok.kill()"
  },
  {
    "objectID": "00-welcome/index.html",
    "href": "00-welcome/index.html",
    "title": "Teaching Finance with AI",
    "section": "",
    "text": "I believe that one of the most important things we can teach business students today is how they can use AI to be more efficient in the workplace. I’ve started this blog and created the site finance-with-ai.org to communicate things I’ve learned about teaching MBA students at Rice University how to do financial analyses using “AI + coding” and more broadly how generative AI can and is being used in the finance industry. I will post short notes on what I’ve learned about teaching this topic and on related things I find interesting. The blog is intended to be a resource for finance instructors at the undergraduate, MBA, and MSF levels.\nThe current effectiveness of AI + coding varies somewhat between corporate finance and investments applications. Here, I lump fundamental security analysis with corporate finance. There are many topics in the investments area for which spreadsheets were never well equipped and for which spreadsheets are seldom used in practice. Previously, it was difficult to teach those topics by example, but now students can prompt an LLM to generate code for them.\nEven in capital budgeting, financial statement analysis, and pro forma financial valuation, AI is already very valuable. It is not yet ready to replace spreadsheets, but it can be a useful complement to spreadsheets. AI can be used as a collaborator – “tell me how you would do this” or “you do it your way, and I’ll do it my way, and then we can compare answers.” As the models improve, I expect the world to shift more and more to AI in lieu of spreadsheets even for corporate finance applications. Of course, Hewlett-Packard is still making the 12C financial calculator, and Microsoft will undoubtedly sell Excel for many years to come, but I think AI + coding will eventually dominate. To prepare our students for that world and to give them a leg up, we should teach them what they can do now and what may lie ahead.\nIt is hard to keep up in this rapidly evolving world. Please help by sharing with me and others in the comments.\n\nAlso on substack at kerryback.substack.com"
  },
  {
    "objectID": "index.html#prompt-engineering",
    "href": "index.html#prompt-engineering",
    "title": "",
    "section": "1. Prompt Engineering",
    "text": "1. Prompt Engineering\nA good demonstration at the start of a course on Finance with AI is to upload a company’s annual report to ChatGPT (or a different chatbot) and ask it for an investment analysis in the form of a Word document. You can ask the chatbot to include the following:\n\na summary of the annual report\na comparison of the firm to peer firms\na two-stage DCF analysis formed by extrapolating trends\na sensitivity analysis focused on the items for which extrapolation might be most unreasonable\na buy/hold/sell recommendation\n\nThis example illustrates the power of AI ‘out of the box’ for financial analysis. It also explains why we are seeing so many stories about the potential demise of junior financial analysts. Of course, the AI is not perfect. We should engage our students in a discussion of how the report can be improved.\nCompile the responses to build a more detailed prompt than the original prompt, start a new chatbot session (so the model will have no memory of the original prompt and response1), and submit the new prompt. Compare the results. Get students to discuss how they might further improve the new prompt. Then, point out that the eventual prompt that they form through this iterative process can be saved as a text file and uploaded each time they want to generate this type of report. This is prompt engineering."
  },
  {
    "objectID": "index.html#corporate-implementation-of-ai",
    "href": "index.html#corporate-implementation-of-ai",
    "title": "",
    "section": "2. Corporate Implementation of AI",
    "text": "2. Corporate Implementation of AI\nThe HBS case about Implementing AI at Deloitte is a good foundation for a class discussion of AI implementation. It covers the issues of data privacy, compliance, client trust, reliability, biases, and employee buy-in. It also describes how Deloitte set up a custom chatbot.\nThis widely cited MIT Study is also must reading. It has been described in the media as reporting that 95% of corporate AI implementations fail. What it actually says is that only 5% of corporate AI pilots reach production, which is not quite the same thing. The reasons that most pilots are abandoned and the characteristics of successful pilots are informative. Also key is this passage: “workers from over 90% of the companies we surveyed reported regular use of personal AI tools for work tasks. In fact, almost every single person used an LLM in some form for their work.” So, AI is being widely used, despite the difficulties companies have faced in designing and implementing company-specific AI solutions."
  },
  {
    "objectID": "index.html#ai-generated-code",
    "href": "index.html#ai-generated-code",
    "title": "",
    "section": "3. AI-Generated Code",
    "text": "3. AI-Generated Code\nTwo good exercises for seeing how AI-generated code can be used to perform financial analysis are mean-variance analysis and CAPM cost of capital calculations. I demo the first and assign the second as a group project. AI can write code to get data from Yahoo Finance, calculate returns, and perform the analyses, assuming we are willing to trust sample moments in mean-variance analysis. We could also input risk and risk premia assumptions directly for mean-variance analysis rather than calculating sample moments. See my blog posts about getting data from Yahoo Finance, mean-variance analysis, and calculating the cost of capital.\nThere are natural visualization components to both exercises, namely the plot of the mean-variance frontier and the CAPM scatter plot and regression line. AI can write python code to generate Word docs and/or PowerPoint decks containing the analyses and visualizations. See this post about generating Word docs and PowerPoint decks and this post about visualizations.\nThere is a lot that could be done on option pricing if students have seen options already. As remarked above, I teach a first-year class, and I can’t preempt what will be taught to second-year students. Except for that issue, I would certainly spend some time on options."
  },
  {
    "objectID": "index.html#building-apps",
    "href": "index.html#building-apps",
    "title": "",
    "section": "4. Building Apps",
    "text": "4. Building Apps\nWhatever code an LLM (large language model) writes for an exercise in Part 1 can be encapsulated in an app and made broadly available, so people can use the code without needing to go to Julius or Colab or any other Python platform. The Python Streamlit library makes app construction easy. The same is true of the Gradio library apparently, but I only have experience with Streamlit. See my blog post about creating apps. Again, I demo mean-variance analysis and assign cost of capital calculations as a group project.\nStreamlit apps can be deployed to the cloud from Google Colab using the ngrok service. Students will need to create free accounts at ngrok and get an authorization token. They should save their authorization tokens as secret keys in Google Colab (they can ask Gemini how to do that). Then, they can tell Gemini to deploy apps using ngrok.\nAt this point in the course, students have seen enough to compare the following ways to perform a financial analysis:\n\nUsing Excel\nAsking a chatbot\nUsing AI + coding via Google Colab’\nCreating and using an app\n\nThis provides the foundation for an informative class discussion about the relative merits of each approach and the circumstances in which one approach is better than another."
  },
  {
    "objectID": "index.html#building-chatbots",
    "href": "index.html#building-chatbots",
    "title": "",
    "section": "5. Building Chatbots",
    "text": "5. Building Chatbots\nCustom chatbots involve\n\nA user interface\nAn API connection to an LLM\nA customization of user prompts\n\nSystem prompt\nPossible retrieval of documents\n\nPossible uses of tools\nPossible fine tuning\n\nCreating a user interface is a variation of building an app and has already been essentially covered. Creating an API connection to an LLM is similar to setting up ngrok as covered in the second topic. Finally, the prompt that was saved as a text file in the course introduction can easily be used to create an example of a system prompt. So, a simple custom chatbot of user interface + API connection + system prompt requires only techniques that students have already seen at this point.\nStudents can get API keys from OpenAI even with free accounts, or they can get API keys from Anthropic or Google. They can ask any chatbot how to do it. They should save their API keys as secret keys in Google Colab in the same way they saved their ngrok keys. They will be charged on a per-usage basis, but the charges will be trivial for the experimentation that is done in the course. It is also possible to get a free API key from Open Router and to use free open source LLMS from Hugging Face, so there are no charges at all.\nOnce an API key is installed on Colab, students can ask Gemini to connect to the LLM and send a prompt and get a response. Gemini will probably import the openai Python package even for using other LLMs, because the OpenAI API has become the standard. The code that Gemini has to write to use the openai package is extremely simple and transparent, and it is useful for students to see it.\nAs a next step, students can ask Gemini in Google Colab to create a custom chatbot using Streamlit and ngrok. A good example for a system prompt is to ask the LLM to respond in a foreign language, so students can see that the system prompt actually works. It is important that Gemini build a loop in the app that collects all past prompts and responses and sends them together with the system prompt with each new prompt. If the chatbot does not seem to be remembering past prompts during a session, it is because the loop was not constructed. Students should ask Gemini to add the loop if this occurs.\nFor a first financial chatbot, we can return to the mean-variance or cost of capital exercise. The apps created before can be recreated as chatbots, so users can ask for what they want in natural language instead of using input fields on an app. Here, I use OpenAI’s API with the Code Interpreter tool enabled. The code that performed the calculations in the app can be uploaded in the system prompt with instructions to run it with the Code Interpreter to answer the user’s questions.\nThe mean-variance analysis and cost of capital calculations are simple examples, but they provide a good foundation to discuss the following questions.\n\nFor what types of analyses would a custom chatbot work better than an app?\nFor what types of analyses is it worthwhile to create a custom chatbot rather than using a standard chatbot?"
  },
  {
    "objectID": "index.html#ai-assisted-dcf-valuation",
    "href": "index.html#ai-assisted-dcf-valuation",
    "title": "",
    "section": "7. AI-Assisted DCF Valuation",
    "text": "7. AI-Assisted DCF Valuation\nWe start the course by asking a chatbot to do a DCF analysis. We can return to the same question now with new tools in our belt. A good question to pose is: How can we best build a chatbot to assist us in valuing a company? At least a week and perhaps two weeks should be dedicated to this question.\nI like the HBS case Valuing Walmart 2010. The approach that the case guides students to use is too simplistic, so I mostly ignore it. I like the case because all students will have some understanding of where Walmart’s value comes from, and we can have meaningful discussions of possible future growth rates.\nI start this part of the course by sketching a valuation analysis on the board with student input and discussion. We have to decide what ratios and growth rates we will use to generate pro forma statements and what assumptions we will make about them. This provides a leveling-up experience for students and provides focus to the ensuing discussions.\nAfter working through the issues by hand, I upload the financial statements in the case to ChatGPT and ask it for a DCF valuation. Then, I read the statements into Google Colab and ask Gemini to assist with a valuation in Python. At this point, students are prepared to discuss whether and how we can create a useful valuation assistant using an app or custom chatbot.\nTo use the app or custom chatbot, we will need to have a data source. It is easy to get data from Yahoo Finance. Alternatively, users can be asked to upload data. It may also be possible to use other data sources, if there are available sources with APIs that can be used by the chatbot.\nI assign the creation of a valuation assistant chatbot as the final group project for the course, worth 50% of the total grade. I require the chatbots to include a facility for uploading financial statements.\nI use the last class day for testing and demonstrations. I give each group the same company and data to evaluate and give them a fixed amount of time to use their assistants to attempt generate a valuation (breaking out into groups). Then, we reconvene, and each group shows the class how their tool performed, by scrolling through their chat history and explaining their process."
  },
  {
    "objectID": "index.html#corporate-implementations-of-ai",
    "href": "index.html#corporate-implementations-of-ai",
    "title": "",
    "section": "2. Corporate Implementations of AI",
    "text": "2. Corporate Implementations of AI\nThe HBS case about Implementing AI at Deloitte is a good foundation for a class discussion of AI implementation. It covers the issues of data privacy, compliance, client trust, reliability, biases, and employee buy-in. It also describes how Deloitte set up a custom chatbot.\nThis widely cited MIT Study is also must-reading. It has been described in the media as reporting that 95% of corporate AI implementations fail. What it actually says is that only 5% of corporate AI pilots reach production, which is not quite the same thing. The reasons that most pilots are abandoned and the characteristics of successful pilots are informative. Also key is this passage: “workers from over 90% of the companies we surveyed reported regular use of personal AI tools for work tasks. In fact, almost every single person used an LLM in some form for their work.” So, AI is being widely used, despite the difficulties companies have faced in designing and implementing company-specific AI solutions.\nAnother very interesting item is this study about the use of AI in corporate teams. The study is described by one of the authors here. They conclude that, instead of thinking of AI as a tool, it should be regarded as a teammate. They find that one person working with AI is at least as efficient as two people working in a team without AI. The most effective combination is naturally a team with AI. Interestingly, they find that AI enables workers and teams to break functional silos, performing like teams composed of individuals with diverse functional knowledge."
  },
  {
    "objectID": "index.html#extras",
    "href": "index.html#extras",
    "title": "",
    "section": "Extras",
    "text": "Extras\n\nIntroduction to Python\nStudents need to have some understanding of what they are seeing when an LLM generates code. I provide a pre-course workshop on using Jupyter notebooks in Google Colab, basic elements of Python, and pandas, numpy, and visualization libraries\n\n\nBeyond Streamlit\nStreamlit is a convenient way to build apps, but it provides limited flexibility in the design of the user interface. LLMs can write code in many languages other than Python. [Replit] is an easy-to-use platform for creating apps that codes in Python, JavaScript, HTML, CSS, and other languages to create professional user interfaces. I don’t ask students to subscribe, but I do provide a demonstration.\n\n\nDatabase Chatbots\nAnother example of a useful custom chatbot is one that converts natural language prompts into database queries and returns data. To demonstrate this, we first need to store a database online. We can use CRSP and/or Compustat data or other data for this example. An easy way to create an online database is to create an account at MotherDuck and use the MotherDuck CLI to upload csv files. ChatGPT or Gemini can tell you how to do this, or, there are agentic chatbots like Claude Code that can do it for you. Then, we can ask Gemini (or Replit) to create a chatbot that (i) sends a user prompt to an LLM, (ii) receives a response in the form of SQL code, (iii) sends the SQL code to MotherDuck to retrieve data, and (iv) returns the data to the user. The key to this is the duckdb Python library, that can execute SQL queries against csv files just as if a SQL database had been set up. To create the chatbot, a system prompt must be created that adequately describes the csv file to the LLM. This will probably require testing and iteration.\n\n\nApp Deployment\nTo permanently deploy an app, we need an account at a host. Koyeb is a good choice. Render is similar. A relatively simple way to deploy is to also create a GitHub account. Then, you can\n\nInitialize a GitHub repository\nPush your code to GitHub\nAdd a new Koyeb or Render service\nConnect the service to the GitHub repository\nClick ‘Deploy’ on Koyeb or Render\n\nGemini or another chatbot can walk you through each step.\n\n\nLocal Installation of AI + Coding\nThe simplest way for students to install Python plus some of the packages they need is to use the Anaconda distribution. It is free and easy to use.\nTo create a local version of Google Colab with Gemini, it is hard to beat Cursor. Cursor is offering students a free year of its Cursor Pro account. Students can use their OpenAI API keys - or API keys from Anthropic or Google, etc. - to configure the AI. There will be charges based on usage.\nCursor has auto-complete and chat just like Google Colab. It can also execute terminal commands. Using the terminal, it can implement the steps described above for permanent deployment of apps - creating a Github repo, pushing to Github, integrating with Koyeb or Render, and deploying. This is even easier than asking a chatbot what to do and doing it yourself.\nCursor can also code in other languages than Python. So, it can use JavaScript, etc. to create professional user interfaces, as discussed above for Replit."
  },
  {
    "objectID": "index.html#custom-chatbots",
    "href": "index.html#custom-chatbots",
    "title": "",
    "section": "5. Custom Chatbots",
    "text": "5. Custom Chatbots\nCustom chatbots involve\n\nA user interface\nAn API connection to an LLM, which has possibly been fine-tuned\nA customization of user prompts\n\nSystem prompt\nPossible retrieval of documents\n\nPossible uses of tools\n\nCreating a user interface is a variation of building an app and has already been essentially covered. Creating an API connection to an LLM is similar to setting up ngrok as covered in the second topic. Finally, the prompt that was saved as a text file in the course introduction can easily be used to create an example of a system prompt. So, a simple custom chatbot of user interface + API connection + system prompt requires only techniques that students have already seen at this point.\nStudents can get API keys from OpenAI even with free accounts, or they can get API keys from Anthropic or Google. They can ask any chatbot how to do it. They should save their API keys as secret keys in Google Colab in the same way they saved their ngrok keys. They will be charged on a per-usage basis, but the charges will be trivial for the experimentation that is done in the course. They could also get free API keys from Open Router and use free open source LLMS from Hugging Face.\nOnce an API key is installed on Colab, students can ask Gemini to connect to the LLM and send a prompt and get a response. Gemini will import the openai Python package even for using other LLMs, because the OpenAI API has become the standard. The code that Gemini has to write to use the openai package is extremely simple and transparent, and it is useful for students to see it.\nAs a next step, students can ask Gemini to create a custom chatbot using Streamlit and ngrok. A good example for a system prompt is to ask the LLM to respond in a foreign language, so we can see that the system prompt actually works. It is important that Gemini build a loop in the app that collects all past prompts and responses and sends them together with the system prompt with each new prompt. If the chatbot does not seem to be remembering past prompts during a session, it is because the loop was not constructed. Students should ask Gemini to add the loop if this occurs."
  },
  {
    "objectID": "index.html#ai-agents",
    "href": "index.html#ai-agents",
    "title": "",
    "section": "6. AI Agents",
    "text": "6. AI Agents\nAn AI agent is a chatbot that can use tools to complete tasks. Unlike regular chatbots that only generate text, agents can call functions, access APIs, and run applications to get things done.\nStudents are prepared to learn about AI agents after having seen app development and custom chatbot development. We can configure the mean-variance and cost-of-capital apps as tools that can be called and create a custom chatbot that can call them. All of this can be done by Gemini in Google Colab.\nIf we connect multiple tools to a chatbot, then a user can, within a single chatbot session, perform a variety of specialized tasks. For example, a user can retrieve data, possibly from multiple sources, and perform multiple types of analyses, all while interacting with the same chatbot using natural language prompts. This really unleashes the power of AI."
  },
  {
    "objectID": "index-old.html",
    "href": "index-old.html",
    "title": "",
    "section": "",
    "text": "The purpose of this site is to share some experiences and thoughts about teaching MBA students how generative AI can and is being used in the finance industry and how they can leverage it to be more efficient in the workplace. We are all learning this on the fly, and of course things are evolving very quickly, so I’m hoping that sharing will be useful. I invite everyone to share in the comments section below.\nI teach a six-week 18-contact-hour course to first year MBAs in the last part of their first year. For the most part, I do not teach new financial concepts in the course, because we have other courses for those. However, I try to reinforce students’ understanding of concepts they have already seen by approaching them with a different tool (AI + coding). The course caps a first-year sequence consisting of a one-semester core course in the fall followed by an ‘Applied Finance’ course in the first part of the spring that goes deeper into some of the topcs covered in the core course and develops spreadsheet modeling skills, and then my course in the last part of the spring that covers the same topics again, but using AI + coding instead of spreadsheets. I will describe that course in particular, but many of the observations below should apply to courses in other formats and to courses for different student groups."
  },
  {
    "objectID": "index-old.html#tools",
    "href": "index-old.html#tools",
    "title": "",
    "section": "Tools",
    "text": "Tools\nStudents can use any chatbot for the first part of the course. Then, the course switches to using Google Colab, which is a free Python environment in the cloud that has built-in Google Gemini assistance. There is no software to install, so there is no set-up required. I prepared some materials to show students how to use Google Colab, which I cover when we get to that point.\nFor the last part of the course, students need an OpenAI account. They can use the free version. They will need to get an API key, for which charges are on a per-usage basis. The charges are minimal for the experimentation that is done in the course.\nPreviously, I used Julius.ai instead of Google Colab It is a bit simpler to use, because it is a simple chatbot interface rather than a Jupyter notebook - see my blog post about Julius. Julius also provides access to LLMs from OpenAI and Anthropic, whereas Colab only offers Google Gemini. However, while Anthropic’s Claude is still the best coding LLM, Gemini has caught up considerably and is now a solid choice. Furthermore, Colab offers several advantages: it is free, it produces Jupyter notebooks that are portable, and it can deploy apps to the cloud."
  },
  {
    "objectID": "index-old.html#main-topics",
    "href": "index-old.html#main-topics",
    "title": "",
    "section": "Main Topics",
    "text": "Main Topics\nThe course covers the following topics:\n\nPrompt engineering\nCorporate implementations of AI\nUsing AI to write code for financial analysis, visualization, and report generation\nUsing AI to create apps to automate the above\nUsing AI to create custom chatbots for the above\nUnderstanding AI agents and their capabilities\nIn-depth study of using AI for DCF valuation of companies"
  },
  {
    "objectID": "index-old.html#prompt-engineering",
    "href": "index-old.html#prompt-engineering",
    "title": "",
    "section": "1. Prompt Engineering",
    "text": "1. Prompt Engineering\nA good demonstration at the start of a course on Finance with AI is to upload a company’s annual report to ChatGPT (or a different chatbot) and ask it for an investment analysis in the form of a Word document. You can ask the chatbot to include the following:\n\na summary of the annual report\na comparison of the firm to peer firms\na two-stage DCF analysis formed by extrapolating trends\na sensitivity analysis focused on the items for which extrapolation might be most unreasonable\na buy/hold/sell recommendation\n\nThis example illustrates the power of AI ‘out of the box’ for financial analysis. It also explains why we are seeing so many stories about the potential demise of junior financial analysts. Of course, the AI is not perfect. We should engage our students in a discussion of how the report can be improved.\nCompile the responses to build a more detailed prompt than the original prompt, start a new chatbot session (so the LLM will have no memory of the original prompt and response1), and submit the new prompt. Compare the results. Get students to discuss how they might further improve the new prompt. Then, point out that the eventual prompt that they form through this iterative process can be saved as a text file and uploaded each time they want to generate this type of report. This is prompt engineering."
  },
  {
    "objectID": "index-old.html#corporate-implementations-of-ai",
    "href": "index-old.html#corporate-implementations-of-ai",
    "title": "",
    "section": "2. Corporate Implementations of AI",
    "text": "2. Corporate Implementations of AI\nThe HBS case about Implementing AI at Deloitte is a good foundation for a class discussion of AI implementation. It covers the issues of data privacy, compliance, client trust, reliability, biases, and employee buy-in. It also describes how Deloitte set up a custom chatbot.\nThis widely cited MIT Study is also must reading. It has been described in the media as reporting that 95% of corporate AI implementations fail. What it actually says is that only 5% of corporate AI pilots reach production, which is not quite the same thing. The reasons that most pilots are abandoned and the characteristics of successful pilots are informative. Also key is this passage: “workers from over 90% of the companies we surveyed reported regular use of personal AI tools for work tasks. In fact, almost every single person used an LLM in some form for their work.” So, AI is being widely used, despite the difficulties companies have faced in designing and implementing company-specific AI solutions.\nAnother very interesting study is this study about the use of AI in corporate teams. The study is described by one of the authors here. They conclude that, instead of thinking of AI as a tool, it should be regarded as a teammate. They find that that one person working with AI is at least as efficient as two people working in a team without AI. The most effective combination is naturally a team with AI. Interestingly, they find that AI enables workers and teams to break functional silos, performing like teams composed of individuals with diverse functional knowledge."
  },
  {
    "objectID": "index-old.html#ai-generated-code",
    "href": "index-old.html#ai-generated-code",
    "title": "",
    "section": "3. AI-Generated Code",
    "text": "3. AI-Generated Code\nTwo good exercises for seeing how AI-generated code can be used to perform financial analysis are mean-variance analysis and CAPM cost of capital calculations. I demo the first and assign the second as a group project. AI can write code to get data from Yahoo Finance, calculate returns, and perform the analyses, assuming we are willing to trust sample moments in mean-variance analysis. We could also input risk and risk premia assumptions directly for mean-variance analysis rather than calculating sample moments. See my blog posts about getting data from Yahoo Finance, mean-variance analysis, and calculating the cost of capital.\nThere are natural visualization components to both exercises, namely the plot of the mean-variance frontier and the CAPM scatter plot and regression line. AI can write python code to generate Word docs and/or PowerPoint decks containing the analyses and visualizations. See this post about generating Word docs and PowerPoint decks and this post about visualizations.\nThere is a lot that could be done on option pricing if students have seen options already. As remarked above, I teach a first-year class, and I can’t preempt what will be taught to second-year students. Except for that issue, I would certainly spend some time on options."
  },
  {
    "objectID": "index-old.html#building-apps",
    "href": "index-old.html#building-apps",
    "title": "",
    "section": "4. Building Apps",
    "text": "4. Building Apps\nWhatever code an LLM writes for an exercise in Part 1 can be encapsulated in an app and made broadly available, so people can use the code without needing to go to Julius or Colab or any other Python platform. The Python Streamlit library makes app construction easy. The same is true of the Gradio library apparently, but I only have experience with Streamlit. See my blog post about creating apps.\nStreamlit apps can be deployed to the cloud from Google Colab using the ngrok service. Students will need to create free accounts at ngrok and get an authorization token. They should save their authorization tokens as secret keys in Google Colab (they can ask Gemini how to do that). Then, they can tell Gemini to deploy apps using ngrok.\nDeployment by ngrok is sufficient to illustrate the concept of building apps, but it is not a permanent deployment. It is probably best to leave permanent deployment as something for students to explore on their own or perhaps to cover in a special session, because it can be a bit complex. The best solution I have found is to install Claude Code and ask it to do it. However, students will need assistance even to install and use Claude Code. See my discussion of setting up and installing Claude Code.\nAt this point in the course, students have seen enough to compare the following ways to perform a financial analysis:\n\nUsing Excel\nAsking a chatbot\nUsing AI + coding via Google Colab’\nCreating and using an app\n\nThis provides the foundation for an informative class discussion about the relative merits of each approach and the circumstances in which one approach is better than another."
  },
  {
    "objectID": "index-old.html#custom-chatbots",
    "href": "index-old.html#custom-chatbots",
    "title": "",
    "section": "5. Custom Chatbots",
    "text": "5. Custom Chatbots\nCustom chatbots involve\n\nA user interface\nAn API connection to an LLM\nA customization of user prompts\n\nSystem prompt\nPossible retrieval of documents\n\nPossible uses of tools\nPossible fine tuning\n\nCreating a user interface is a variation of building an app and has already been essentially covered. Creating an API connection to an LLM is similar to setting up ngrok as covered in the second topic. Finally, the prompt that was saved as a text file in the course introduction can easily be used to create an example of a system prompt. So, a simple custom chatbot of user interface + API connection + system prompt requires only techniques that students have already seen at this point.\nStudents can get API keys from OpenAI even with free accounts, or they can get API keys from Anthropic or Google. They can ask any chatbot how to do it. They should save their API keys as secret keys in Google Colab in the same way they saved their ngrok keys. They will be charged on a per-usage basis, but the charges will be trivial for the experimentation that is done in the course. It is also possible to get a free API key from Open Router and to use free open source LLMS from Hugging Face, so there are no charges at all.\nOnce an API key is installed on Colab, students can ask Gemini to connect to the LLM and send a prompt and get a response. Gemini will probably import the openai Python package even for using other LLMs, because the OpenAI API has become the standard. The code that Gemini has to write to use the openai package is extremely simple and transparent, and it is useful for students to see it.\nAs a next step, students can ask Gemini in Google Colab to create a custom chatbot using Streamlit and ngrok. A good example for a system prompt is to ask the LLM to respond in a foreign language, so students can see that the system prompt actually works. It is important that Gemini build a loop in the app that collects all past prompts and responses and sends them together with the system prompt with each new prompt. If the chatbot does not seem to be remembering past prompts during a session, it is because the loop was not constructed. Students should ask Gemini to add the loop if this occurs.\nFor a first financial chatbot, we can return to the mean-variance or cost of capital exercise. The apps created before can be recreated as chatbots, so users can ask for what they want in natural language instead of using input fields on an app. Here, I use OpenAI’s API with the Code Interpreter tool enabled. The code that performed the calculations in the app can be uploaded in the system prompt with instructions to run it with the Code Interpreter to answer the user’s questions.\nThe mean-variance analysis and cost of capital calculations are simple examples, but they provide a good foundation to discuss the following questions.\n\nFor what types of analyses would a custom chatbot work better than an app?\nFor what types of analyses is it worthwhile to create a custom chatbot rather than using a standard chatbot?"
  },
  {
    "objectID": "index-old.html#ai-agents",
    "href": "index-old.html#ai-agents",
    "title": "",
    "section": "6. AI Agents",
    "text": "6. AI Agents\nAn AI agent is a more sophisticated form of AI assistant that can autonomously perform complex, multi-step tasks with minimal human intervention. Unlike traditional chatbots that respond to prompts one at a time, agents can break down complex problems, create plans, execute multiple steps, use various tools, and adapt their approach based on intermediate results.\n\nKey Characteristics of AI Agents\nAutonomy: Agents can work independently once given a goal. For example, instead of asking step-by-step how to value a company, you could tell an agent “Perform a DCF valuation of Apple” and it would autonomously gather data, perform calculations, create visualizations, and generate a report.\nTool Use: Agents can use multiple tools and APIs. A financial analysis agent might use Yahoo Finance for data, Python for calculations, web search for industry information, and document generation tools for creating reports - all without explicit instructions for each step.\nPlanning and Reasoning: Agents create and execute plans. Given a task like “Compare the financial health of three tech companies,” an agent would plan the analysis approach, determine what metrics to calculate, and decide how to present the comparison.\nMemory and Context: Advanced agents maintain context across sessions and can learn from past interactions, making them more effective over time.\n\n\nExamples in Finance\nA portfolio management agent could continuously monitor market conditions, rebalance portfolios based on predetermined criteria, generate performance reports, and alert managers to significant events - all autonomously.\nAn earnings analysis agent could automatically retrieve quarterly reports when released, compare results to analyst expectations, identify key trends and anomalies, and draft an initial analysis report for human review.\n\n\nBuilding Agents\nStudents can experiment with agent frameworks like LangChain or AutoGPT using the OpenAI API. A simple agent can be created by combining: - A planning module that breaks down tasks - Tool-calling capabilities for data retrieval and calculations\n- A execution loop that works through the plan - Error handling and adaptation mechanisms\nWhile we don’t have time to build sophisticated agents in this course, understanding their potential is crucial as they represent the future of AI-assisted financial analysis."
  },
  {
    "objectID": "index-old.html#ai-assisted-dcf-valuation",
    "href": "index-old.html#ai-assisted-dcf-valuation",
    "title": "",
    "section": "7. AI-Assisted DCF Valuation",
    "text": "7. AI-Assisted DCF Valuation\nWe started the course by asking a chatbot to do a DCF analysis. We return to the same question now with new tools in our belt. A good question to pose is: How can we best build a chatbot to assist us in valuing a company? At least a week and perhaps two weeks should be dedicated to this question.\nI like the HBS case Valuing Walmart 2010. The approach that the case guides students to use is too simplistic, so I mostly ignore it. I like the case because everyone has some understanding of where Walmart’s value comes from, and we can have meaningful discussions of possible future growth rates.\nI start this part of the course by sketching a valuation analysis on the board with student input and discussion. We have to decide what ratios and growth rates we will use to generate pro forma statements and what assumptions we will make about them.\nAfter the in-class discussion, I upload the financial statements in the case to ChatGPT and ask it for a DCF valuation. Then, I read the statements into Google Colab and ask Gemini to assist with a valuation. At this point, students are prepared to discuss whether and how we can create a useful valuationassistant using an app or custom chatbot.\nTo use the app or custom chatbot, we will need to have a data source. It is easy to get data from Yahoo Finance. Alternatively, users can be asked to upload data. It may also be possible to use other data sources, if there are available sources with APIs that can be used by the chatbot.\nI assign creating a valuation assistant chatbot as the final group project for the course, worth 50% of the total grade. I require the chatbots to include a facility for uploading financial statements. Also, students must use the OpenAI API with the Code Interpreter tool enabled.\nI use the last class day for testing and demonstrations. I give each group the same company and data to evaluate and give them a fixed amount of time to use their assistants to attempt generate a valuation (breaking out into groups). Then, we reconvene, and each group shows the class how their tool performed, by scrolling through their chat history and explaining their process."
  },
  {
    "objectID": "index-old.html#giscus",
    "href": "index-old.html#giscus",
    "title": "",
    "section": "Discussions",
    "text": "Discussions\nPlease share your thoughts, experiences, or questions about teaching AI-assisted finance in the comments below."
  },
  {
    "objectID": "index-old.html#footnotes",
    "href": "index-old.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLLMs do not actually remember past prompts and responses in a session. Instead the record of past prompts and responses in a session is sent by a chatbot to an LLM along with each new prompt, so that the LLM can use the record of past prompts and responses when generating a new response.↩︎"
  },
  {
    "objectID": "index.html#tools-for-the-course",
    "href": "index.html#tools-for-the-course",
    "title": "",
    "section": "Tools for the Course",
    "text": "Tools for the Course\nStudents can use any chatbot for the first part of the course. Then, the course switches to using Google Colab, which is a free Python environment in the cloud that has built-in Google Gemini assistance. There is no software to install, so there is no set-up required. I prepared some materials to show students how to use Google Colab, which I cover when we get to that point.\nPreviously, I used Julius.ai instead of Google Colab. Julius is a bit more straightforward to use, because it is a simple chatbot interface rather than a Jupyter notebook - see my blog post about Julius. Julius also provides access to models from OpenAI and Anthropic, whereas Colab only offers Google Gemini. However, while Anthropic’s Claude is still the best coding model, Gemini has caught up considerably and is now a solid choice. Furthermore, Colab offers several advantages: it is free, it produces Jupyter notebooks that are portable, and it can deploy apps to the cloud."
  }
]